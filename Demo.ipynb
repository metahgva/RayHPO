{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bba6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is generated by the Domino Code Assist toolbar button\n",
    "import domino_code_assist as dca\n",
    "dca.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e85786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings to make demo look cleaner\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132b3f2",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "The below snippet was generated using DCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/mnt/data/financial-news/data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b43cef",
   "metadata": {},
   "source": [
    "# Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"\")\n",
    "\n",
    "# Encode labels\n",
    "df[\"label\"] = df[\"label\"].replace([\"neutral\",\"positive\",\"negative\"],[0,1,2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3668e99",
   "metadata": {},
   "source": [
    "# Finetune Model\n",
    "\n",
    "The below snippet was generated using DCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import datasets\n",
    "from transformers import BertTokenizer, Trainer, BertForSequenceClassification, TrainingArguments, pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "os.environ[\"MLFLOW_FLATTEN_PARAMS\"] = \"1\"\n",
    "os.environ[\"HF_MLFLOW_LOG_ARTIFACTS\"] = \"1\"\n",
    "\n",
    "label_col = \"label\"\n",
    "text_col = \"sentence\"\n",
    "\n",
    "ds_dict = dca.convert_and_split_data(df, label_col, text_col)\n",
    "df_labels = ds_dict[\"train\"].to_pandas()[label_col].unique().tolist()\n",
    "\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "\n",
    "learning_rate = 0.00001\n",
    "epochs = 3\n",
    "experiment_name = \"finbert\"\n",
    "\n",
    "for split in [\"train\", \"test\", \"validation\"]:\n",
    "    if split in ds_dict:\n",
    "        print(\"Samples in {:<10s}      : {:d}\".format(split, ds_dict[split].shape[0]))\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\" : accuracy_score(predictions, labels)}\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(df_labels))\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def prep_dataset(ds, label_col, text_col):\n",
    "    def to_int(e):\n",
    "        e[label_col] = [df_labels.index(x) for x in e[label_col]]\n",
    "        return e\n",
    "\n",
    "    if \"int\" not in ds.features[label_col].dtype:\n",
    "        ds = ds.map(to_int, batched=True)\n",
    "\n",
    "    ds = ds.map(lambda e: tokenizer(e[text_col], truncation=True, padding=\"max_length\", max_length=315), batched=True)\n",
    "    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", label_col])\n",
    "    return ds\n",
    "\n",
    "for split in [\"train\", \"test\", \"validation\"]:\n",
    "    if split in ds_dict:\n",
    "        ds_dict[split] = prep_dataset(ds_dict[split], label_col, text_col)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"temp\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,\n",
    "    report_to=\"mlflow\",\n",
    "    optim=\"adamw_torch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds_dict[\"train\"],\n",
    "    eval_dataset=ds_dict[\"test\"],\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "exp = mlflow.set_experiment(experiment_name)\n",
    "with mlflow.start_run() as run:\n",
    "    display(dca.automl.OpenExperiment(experiment_name))\n",
    "    trainer.train()\n",
    "    if \"validation\" in ds_dict:\n",
    "        accuracy_test = trainer.predict(ds_dict[\"validation\"]).metrics[\"test_accuracy\"]\n",
    "        print(\"Accuracy on validation: {:.2f}\".format(accuracy_test))\n",
    "    trainer.save_model(\"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1b786",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning With Ray\n",
    "\n",
    "Let's take the above code, refactor it into a python for remote execution, and then add some Ray Tuning logic in order to execute on a cluster.\n",
    "\n",
    "Write the following code into a file and then execute it using `python ray-tuning.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ray-tuning.py\n",
    "import sys\n",
    "import transformers\n",
    "import argparse\n",
    "import os\n",
    "import ray\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from ray import tune, air\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, Trainer, BertForSequenceClassification, TrainingArguments, pipeline, TrainerCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ray.air import session\n",
    "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "os.environ[\"DISABLE_MLFLOW_INTEGRATION\"] = \"TRUE\" # Disabling hugging face MLFlow logger in favor of Ray MLFlow logger \n",
    "\n",
    "print(\"Initializing Ray Cluster...\")\n",
    "service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "ray.init(f\"ray://{service_host}:{service_port}\")\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        # Report metrics to Ray Tune\n",
    "        session.report({\"eval_accuracy\": state.best_metric})\n",
    "\n",
    "def load_data(file_name):\n",
    "    # Load from CSV\n",
    "    df = pd.read_csv(file_name).fillna(\"\")\n",
    "    \n",
    "    # Encode labels\n",
    "    df[\"label\"] = df[\"label\"].replace([\"neutral\",\"positive\",\"negative\"],[0,1,2]) \n",
    "    return df\n",
    "\n",
    "def split(df):\n",
    "    df_train, df_test, = train_test_split(df, stratify=df[\"label\"], test_size=0.1, random_state=42)\n",
    "    df_train, df_val = train_test_split(df_train, stratify=df_train[\"label\"],test_size=0.1, random_state=42)\n",
    "    print(\"Samples in train      : {:d}\".format(df_train.shape[0]))\n",
    "    print(\"Samples in validation : {:d}\".format(df_val.shape[0]))\n",
    "    print(\"Samples in test       : {:d}\".format(df_test.shape[0]))\n",
    "    \n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "\n",
    "def prep_datasets(df_train, df_val, df_test, tokenizer):\n",
    "    dataset_train = Dataset.from_pandas(df_train)\n",
    "    dataset_val = Dataset.from_pandas(df_val)\n",
    "    dataset_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "    dataset_train = dataset_train.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", max_length=315), batched=True)\n",
    "    dataset_val = dataset_val.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\", max_length=315), batched=True)\n",
    "    dataset_test = dataset_test.map(lambda e: tokenizer(e[\"sentence\"], truncation=True, padding=\"max_length\" , max_length=315), batched=True)\n",
    "\n",
    "    dataset_train.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"])\n",
    "    dataset_val.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"])\n",
    "    dataset_test.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"])\n",
    "    \n",
    "    return dataset_train, dataset_val, dataset_test\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\" : accuracy_score(predictions, labels)}\n",
    "\n",
    "def train(config, epochs, data_dir):\n",
    "    df = load_data(data_dir)\n",
    "    df_train, df_val, df_test = split(df)\n",
    "    \n",
    "    model = BertForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\", num_labels=3)\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "    dataset_train, dataset_val, dataset_test = prep_datasets(df_train, df_val, df_test, tokenizer)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=\"./outputs\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=epochs,\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        adam_beta1=config[\"adam_beta1\"],\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=False,\n",
    "        skip_memory_metrics=True,\n",
    "        optim=\"adamw_torch\",\n",
    "        report_to=\"mlflow\",\n",
    "        metric_for_best_model=\"eval_accuracy\",\n",
    "        disable_tqdm=True\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=dataset_train,\n",
    "        eval_dataset=dataset_val,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[CustomCallback()]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    accuracy_test = trainer.predict(dataset_test).metrics[\"test_accuracy\"]\n",
    "    print(\"Test accuracy: {:.2f}\".format(accuracy_test))\n",
    "    trainer.save_model(\"./outputs/model\")\n",
    "\n",
    "def main():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Hyperparameter tuning a FinBERT model using the Sentiment Analysis for Financial News dataset.\")\n",
    "    parser.add_argument(\"--data\", help=\"Path to CSV dataset.\", required=False, default=\"/mnt/data/financial-news/data.csv\", type=str)\n",
    "    parser.add_argument(\"--epochs\", help=\"Training epochs.\", required=False, default=3, type=int)\n",
    "    parser.add_argument(\"--trials\", help=\"Number of trials.\", required=False, default=4, type=int)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    config = {\n",
    "        \"learning_rate\": tune.loguniform(1e-6, 1e-4),\n",
    "        \"weight_decay\": tune.choice([0, 0.1, 0.001]),\n",
    "        \"adam_beta1\": tune.choice([0.9, 0.8])\n",
    "    }\n",
    "\n",
    "    train_fn = tune.with_parameters(train, epochs=args.epochs, data_dir=args.data)\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_fn, resources={\"cpu\": 2, \"gpu\": 1}),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"eval_accuracy\",\n",
    "            mode=\"max\",\n",
    "            num_samples=args.trials\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            name=\"mlflow\",\n",
    "            callbacks=[MLflowLoggerCallback(experiment_name=\"finbert-hyperparameter-tuning\", save_artifact=True)]\n",
    "        ),\n",
    "        param_space=config,\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    print(results)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb313add",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596d12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "from transformers import pipeline\n",
    "\n",
    "def predict_sentiment(sentence):\n",
    "    results = nlp(sentence)\n",
    "    return results[0]\n",
    "\n",
    "run_id = \"40cc9462f14c48a2a436f56298540c65\" # MLFlow Run ID\n",
    "model_path = \"outputs/run-ae192_00001/checkpoint-2460\" # Artifact path of the model\n",
    "model_artifact = mlflow.artifacts.download_artifacts(run_id=run_id, artifact_path=model_path) \n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_artifact,num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "test_sentence = \"there is a shortage of capital, and we need extra financing\"\n",
    "sentiment = predict_sentiment(test_sentence)\n",
    "print(\"sentence   : {}\".format(test_sentence))\n",
    "print(\"prediction : {}\".format(sentiment[\"label\"]))\n",
    "print(\"score      : {}\".format(sentiment[\"score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf030ddd",
   "metadata": {},
   "source": [
    "# Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c90a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "run_id = \"40cc9462f14c48a2a436f56298540c65\" # MLFlow Run ID\n",
    "model_path = \"outputs/run-ae192_00001/checkpoint-2460\" # Artifact name of the model\n",
    "\n",
    "model = mlflow.register_model(\"runs:/{}/{}\".format(run_id, model_path), \"FinBERT\")\n",
    "print(\"Successfully registered model!\")"
   ]
  }
 ],
 "metadata": {
  "dca-init": true,
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
